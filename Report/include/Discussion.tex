\section{Discussion}
\label{discussionSec}

When using the entire bioloid as a type during the pre-evolution generated a somewhat unexpected behaviour in the fitness function, as seen in Figure \ref{fig:fitness_1a}. Since the implementation is using elitism, we would expect the maximum fitness to be non-decreasing. The fitness is measured at the end of a simulated generation, and the correlation is an aggregate of the similarity between the output signal and the reference signal over time. Hence, when using the internal parameters as genome, their performance depend on the earlier input values to the CPG, which are constantly changing between generations as the model is updated. An elite individual can therefore never be guaranteed to be the best individual both in current and in future generations. Compared to using only the weights as genome, where the internal parameters in the GPGs are reset between each simulation run, the individuals always have the same starting conditions for each generation, and the elite individual can be maintained.

Why are these results not better then? To start with, the simulations were only made over maximum 1000 generations with a population size of 30. Even if the fitness function seem to converge already between 100-200 generations, a more conclusive result could be achieved by simulating the model over longer time with higher population size. Also, since the output signal does not adapt to the amplitude of the input signal, one might reason that it could be some problems in the implementation of the CPG or GA models. Building a CPG model with a GA from scratch took a great amount of time. Much of the time was spent to understand the specifics of the models and algorithms and getting a working prototype, and less time was spent optimising the model. With more time, further investigations of the functionality and optimality of the model could be made. Furthermore, it would probably be more reasonable to optimise each DoF independently instead of all DoF collectively in an individual.

If we now look at the walking cycle GA, while the robot does manage to move forward, it is far from the walking cycle captured from the accelerometers. A simple solution might be to just increase the simulation time - after all, given infinite time, surely the simulation would generate a walking cycle? While this is true, there are several other factors that explain the discrepancy by the desired output and the achieved output. The first aspect is the differences between the simulated robot and the physical one. As mentioned before, the friction is a major difference, but also the movement and dynamics of the robot, creating a major reality gap. In real life, the servos of the Bioloid are heavy, quite stiff and unable to move particularly fast. The 3D model, by comparision, is lightweight, with joints that swivel and move far faster than the real robot ever could. Not only does this result in a 3D simulation that is more unstable  (in terms of standing without falling, etc.), but also that the results gained from it is troublesome to translate in the real robot. In the current state, the simulation tends to exploit small, single-joint movements to propel itself forward. But looking at the overall scope of the project, we desire movements that can efficiently transfer the accelerometer data to the simulation, and finally to the real robot. That implies that we need movement cycles robust enough to translate between all three levels, and it is resonable to assume that would be dynamics that utilize quite large movements of several joints together - like moving all the joints in one leg at once. In order to counteract this, it would be well worth the time to fine-tune the Bioloid model and the V-REP enviroment, and making sure the simulation enviroment aligns as closely to the real world as possible. However, not all efforts should be focused on the 3D enviroment either. More care needs to be taken in regards to the GA parameters, and the fitness function used. In the current GA, the fitness function does not sufficiently punish inefficient walking modes, such as favoring one leg over the other, not keeping the torso straight, or moving the arms in a way that counteracts the forward motion. Finally, a deeper  understanding of both GA:s and CPG networks would be required to utilize the full potential of the methods. It is likely that a better choice of parameters in both the GA and CPG would have yielded better results, since they were chosen quite arbitraily in the current implementation. The pre-processing for the CPG weights took a lot of development and simulation time, and in the end the results did not compare to the time spent developing it. It was also not until the later stages of the project that the oscillating input to the Matusoka was considered, where an earlier implementation could have lead to better results and perhaps allowed us to skip the pre-processing of the CPG altogether. It is also possible that a GA does not result in the best performance, and instead some other form of reinforced algorithm should be considered. However, despite all this the simulation showed clear signs of improvement during the runtime. Due to deadlines the simulation runtime was limited, but it would be interesting to see what results a week-long simulation would generate. A common behaviour of GA:s is to be stuck in a behaviour for a considerable amount of time, and then stumble upon a behaviour with considerably higher fitness. Such jumps were not observed in our simulations, reinforcing the idea that the GA needed more fine-tuning, but perhaps also more runtime.